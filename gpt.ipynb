{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- link GitHub Repo\n",
    "- do what's in the video for baseline\n",
    "- try different model hidden dimension or a different optimizer is fine\n",
    "- describe results briefly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Add line so we don't have to reload notebooks for changes in imported modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from helpers.load_data import load_data\n",
    "from helpers.get_batch import get_batch\n",
    "from helpers.estimate_loss import estimate_loss\n",
    "from helpers.tokenizer import Tokenizer\n",
    "from models.gpt import GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x11cd56e10>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "BLOCK_SIZE = 8\n",
    "EVAL_INTERVAL = 100\n",
    "LEARNING_RATE = 1e-3\n",
    "EVAL_ITERS = 200\n",
    "MAX_ITERS = 3000\n",
    "N_EMBED = 32\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "text: str = load_data()\n",
    "\n",
    "tokenizer = Tokenizer(text)\n",
    "data = torch.tensor(tokenizer.encode(text))\n",
    "\n",
    "# Create train and test sets\n",
    "n = int(len(text) * 0.9)\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt = GPT(tokenizer.vocab_size, N_EMBED, BLOCK_SIZE, DEVICE).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, Train loss: 4.3243, Val loss: 4.3317\n",
      "Step 100, Train loss: 2.9656, Val loss: 3.0039\n",
      "Step 200, Train loss: 2.6674, Val loss: 2.6713\n",
      "Step 300, Train loss: 2.5423, Val loss: 2.5363\n",
      "Step 400, Train loss: 2.4699, Val loss: 2.4794\n",
      "Step 500, Train loss: 2.4326, Val loss: 2.4433\n",
      "Step 600, Train loss: 2.3899, Val loss: 2.3782\n",
      "Step 700, Train loss: 2.3569, Val loss: 2.3589\n",
      "Step 800, Train loss: 2.3252, Val loss: 2.3468\n",
      "Step 900, Train loss: 2.2952, Val loss: 2.3004\n",
      "Step 1000, Train loss: 2.2888, Val loss: 2.2835\n",
      "Step 1100, Train loss: 2.2595, Val loss: 2.2697\n",
      "Step 1200, Train loss: 2.2476, Val loss: 2.2553\n",
      "Step 1300, Train loss: 2.2230, Val loss: 2.2448\n",
      "Step 1400, Train loss: 2.2173, Val loss: 2.2471\n",
      "Step 1500, Train loss: 2.2056, Val loss: 2.2309\n",
      "Step 1600, Train loss: 2.1813, Val loss: 2.2036\n",
      "Step 1700, Train loss: 2.1654, Val loss: 2.2111\n",
      "Step 1800, Train loss: 2.1667, Val loss: 2.1878\n",
      "Step 1900, Train loss: 2.1642, Val loss: 2.1974\n",
      "Step 2000, Train loss: 2.1590, Val loss: 2.1852\n",
      "Step 2100, Train loss: 2.1387, Val loss: 2.1756\n",
      "Step 2200, Train loss: 2.1337, Val loss: 2.1705\n",
      "Step 2300, Train loss: 2.1293, Val loss: 2.1698\n",
      "Step 2400, Train loss: 2.1149, Val loss: 2.1624\n",
      "Step 2500, Train loss: 2.1183, Val loss: 2.1558\n",
      "Step 2600, Train loss: 2.1030, Val loss: 2.1590\n",
      "Step 2700, Train loss: 2.1191, Val loss: 2.1513\n",
      "Step 2800, Train loss: 2.0995, Val loss: 2.1309\n",
      "Step 2900, Train loss: 2.1013, Val loss: 2.1361\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=1e-3)\n",
    "\n",
    "for iter in range(MAX_ITERS):\n",
    "    \n",
    "    if iter % EVAL_INTERVAL == 0:\n",
    "        train_loss, val_loss = estimate_loss(\n",
    "            model=gpt, \n",
    "            train_data=train_data,\n",
    "            valid_data=test_data,\n",
    "            block_size=BLOCK_SIZE,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            eval_iters=EVAL_ITERS,\n",
    "            device=DEVICE\n",
    "        )\n",
    "        print(f\"Step {iter}, Train loss: {train_loss:.4f}, Val loss: {val_loss:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch(\n",
    "        train_data,\n",
    "        BLOCK_SIZE, \n",
    "        BATCH_SIZE,\n",
    "        device=DEVICE\n",
    "    )\n",
    "\n",
    "    logits, loss = gpt(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'ORKICE:\n",
      "O my sere where, and pare thees.\n",
      "\n",
      "\n",
      "ALOUCHAFRULES:\n",
      "To not tegUKith.\n",
      "\n",
      "Ay.\n",
      "\n",
      "WINPALIO:\n",
      "Thes ayor hould fTill thomot but o was the be not Reravack itin.\n",
      "\n",
      "DUKES:\n",
      "WiHerage Ef:\n",
      "Iher reariage of me plad weal thy to kisTA:\n",
      "Sir,\n",
      "Ad i nocht whe char hece cile;\n",
      "UTIUS:\n",
      "Is who stalnd. I ghar\n",
      "Ack oull, to pme.\n",
      "Going EYHow, if bere ito on't yriagh shat en copt hell beel!\n",
      "Wher couves, is'm Ben aus loier fand olenfuil\n",
      "By sloo,\n",
      "\n",
      "O,-noch ont\n",
      "In wily thind-nest ceath,\n",
      "Hell ming;\n",
      "And of worg'd veges,\n",
      "No,\n",
      "\n",
      "She\n"
     ]
    }
   ],
   "source": [
    "start_token = torch.zeros((1, 1)).long().to(DEVICE)\n",
    "sequence = gpt.generate(start_token, max_len=500, block_size=BLOCK_SIZE)[0].tolist()\n",
    "print(tokenizer.decode(sequence))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpt-from-scratch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
